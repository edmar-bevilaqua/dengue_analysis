{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e421ec",
   "metadata": {},
   "source": [
    "# Dengue Analysis:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import zipfile\n",
    "import subprocess\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shap\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Scikit-learn - Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Scikit-learn - Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Scikit-learn - Validation and Metrics\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    cross_validate\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# Custom utilities\n",
    "from utils.utils import (\n",
    "    print_with_colors,\n",
    "    is_int,\n",
    "    process_num_like_cols,\n",
    "    print_with_multiple_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b904ae",
   "metadata": {},
   "source": [
    "## Download:\n",
    "---\n",
    "* Download the Dataset from Web if not already downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./raw_data\"):\n",
    "    os.makedirs(\"./raw_data\")\n",
    "\n",
    "if not os.path.exists(\"./raw_data/arbovirus_clinical_data\"):\n",
    "    # Download of .zip file\n",
    "    url = \"https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/2d3kr8zynf-4.zip\"\n",
    "    output = f\"./raw_data/dataset.zip\"\n",
    "    subprocess.run([\"wget\", \"--quiet\", \"--no-check-certificate\", url, \"-O\", output])\n",
    "\n",
    "    # Extraction of .zip file\n",
    "    subprocess.run([\"unzip\", output])\n",
    "    subprocess.run([\"mv\", \"./2d3kr8zynf-4\", \"./raw_data/arbovirus_clinical_data\"])\n",
    "    subprocess.run([\"rm\", output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca0fc1",
   "metadata": {},
   "source": [
    "## Reading the Dataset:\n",
    "---\n",
    "* Using `chunksize` on `pd.read_csv()` method to use less RAM memory during reading\n",
    "\n",
    "<font color='yellow'>Note: if you already have the .parquet file, you can skip to [this](#file) section<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19baebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "missing_values = [\n",
    "    '', ' ', 'NA', 'N/A', 'NULL',\n",
    "    'ID_AGRAVO', 'DT_NOTIFIC', 'SEM_NOT', 'NU_ANO', 'SG_UF_NOT',\n",
    "    'ID_MUNICIP', 'ID_REGIONA', 'ID_UNIDADE', 'DT_SIN_PRI', 'SEM_PRI',\n",
    "    'DT_NASC', 'NU_IDADE_N', 'CS_SEXO', 'CS_GESTANT', 'CS_RACA',\n",
    "    'CS_ESCOL_N', 'SG_UF', 'ID_MN_RESI', 'ID_RG_RESI', 'ID_PAIS',\n",
    "    'DT_INVEST', 'FEBRE', 'MIALGIA', 'CEFALEIA', 'EXANTEMA',\n",
    "    'VOMITO', 'NAUSEA', 'DOR_COSTAS', 'CONJUNTVIT', 'ARTRITE',\n",
    "    'ARTRALGIA', 'PETEQUIA_N', 'LEUCOPENIA', 'LACO', 'DOR_RETRO',\n",
    "    'DIABETES', 'HEMATOLOG', 'HEPATOPAT', 'RENAL', 'HIPERTENSA',\n",
    "    'ACIDO_PEPT', 'AUTO_IMUNE', 'RESUL_SORO', 'RESUL_NS1', 'RESUL_VI_N',\n",
    "    'RESUL_PCR_', 'HISTOPA_N', 'IMUNOH_N', 'HOSPITALIZ', 'TPAUTOCTO',\n",
    "    'COUFINF', 'COPAISINF', 'COMUNINF', 'CLASSI_FIN', 'EVOLUCAO', 'DT_ENCERRA', '.'\n",
    "]\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Low memory safe reading of the CSV file\n",
    "splitted_df = pd.read_csv(\n",
    "    './raw_data/arbovirus_clinical_data/dengue.csv',\n",
    "    sep=',',\n",
    "    header=0,\n",
    "    na_values=missing_values,\n",
    "    chunksize=100_000,\n",
    ")\n",
    "\n",
    "# Concatenate all chunks into a single DataFrame\n",
    "dengue_df = pd.concat(splitted_df, ignore_index=True)\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283ad20d",
   "metadata": {},
   "source": [
    "* The file `attributes.csv` has important information about the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_csv(\"raw_data/arbovirus_clinical_data/attributes.csv\", sep=\",\", header=0, low_memory=False)\n",
    "attributes = attributes.ffill()\n",
    "attributes = attributes.groupby([\"Attribute\", \"Description\"])[\"Value\"].apply('; '.join).reset_index(name=\"Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df4c0d",
   "metadata": {},
   "source": [
    "## Pre Processing\n",
    "---\n",
    "### Null Data Removal:\n",
    "* Features with frequency > 60% of null values are dropped.\n",
    "* Also, columns like `[\"CS_FLXRET\", \"TP_SISTEMA\", \"CRITERIO\", \"TP_NOT\", \"Unnamed: 0\"]` doesn't have useful information, therefore they can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df = dengue_df.loc[:, dengue_df.isnull().mean() < .60]\n",
    "dengue_df = dengue_df.drop(columns=[\"CS_FLXRET\", \"TP_SISTEMA\", \"CRITERIO\", \"TP_NOT\", \"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffac3f37",
   "metadata": {},
   "source": [
    "* Printing unique values for each feature to check their data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a82172",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dengue_df.columns.to_list():\n",
    "    if str(col) in attributes[\"Attribute\"].to_list():\n",
    "        print(f\"Column '{col}' has {dengue_df[col].unique().size} unique values.\")\n",
    "        if dengue_df[col].unique().size < 50:\n",
    "            print(dengue_df[col].unique(), end=\"\\n\\n\")\n",
    "        else:\n",
    "            print(\"To many unique values, skipping...\", end=\"\\n\\n\")\n",
    "    else:\n",
    "        print_with_colors(f\"Column '{col}' not in attributes. Skipping display...\", \"yellow\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca4d49",
   "metadata": {},
   "source": [
    "* Correlation matrix to check for dependent or exclusive variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c35a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = dengue_df.select_dtypes(include=['number'])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Plotar o heatmap\n",
    "plt.figure(figsize=(24, 20))\n",
    "sns.heatmap(correlation_matrix, annot=True, mask=mask, fmt=\".2f\", cmap=\"Blues\", square=True)\n",
    "plt.title(\"Matriz de Correlação - Variáveis Numéricas\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b943b83",
   "metadata": {},
   "source": [
    "* Count of `NU_ANO` using percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d24894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentual counting\n",
    "percents = dengue_df['NU_ANO'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Format to 2 decimal places\n",
    "percents = percents.round(2)\n",
    "\n",
    "print(percents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc079254",
   "metadata": {},
   "source": [
    "* Distribution of cases per year and `CLASSI_FIN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 6))\n",
    "sns.countplot(data=dengue_df, x='NU_ANO')\n",
    "plt.title('Distribution of cases per year and final classification')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of cases')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a07904",
   "metadata": {},
   "source": [
    "* Distribution of cases per `CLASSI_FIN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df['CLASSI_FIN'] = dengue_df[dengue_df['CLASSI_FIN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd712012",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df = dengue_df[dengue_df['CLASSI_FIN'] != 6.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=dengue_df, x='CLASSI_FIN')\n",
    "plt.title('Distribution of cases per final classification')\n",
    "plt.xlabel('Final Classification')\n",
    "plt.ylabel('Number os cases')\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18200c2",
   "metadata": {},
   "source": [
    "### Standardization of column values:\n",
    "* Since the system has changed over the year, multiple codes were used to represent some types of Dengue. In the cell below we standardized these problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df['CLASSI_FIN'] = dengue_df['CLASSI_FIN'].astype('object')\n",
    "\n",
    "# Mappings to 'Dengue'\n",
    "dengue_df.loc[dengue_df['CLASSI_FIN'].isin([1, 10]), 'CLASSI_FIN'] = 'Dengue'\n",
    "\n",
    "# Mappings to other classes\n",
    "dengue_df.loc[dengue_df['CLASSI_FIN'].isin([3, 4, 12]), 'CLASSI_FIN'] = 'Dengue Grave'\n",
    "dengue_df.loc[dengue_df['CLASSI_FIN'].isin([2, 11]), 'CLASSI_FIN'] = 'Dengue com sinais de alarme'\n",
    "dengue_df.loc[dengue_df['CLASSI_FIN'].isin([5, 6, 8]), 'CLASSI_FIN'] = 'Discarded/Inconclusive'\n",
    "\n",
    "# Filling nan values with the negative class\n",
    "dengue_df['CLASSI_FIN'] = dengue_df['CLASSI_FIN'].fillna('Discarded/Inconclusive')\n",
    "\n",
    "# Converting to category dtype\n",
    "dengue_df = dengue_df[dengue_df['CLASSI_FIN'].isin(['Dengue', 'Discarded/Inconclusive'])]\n",
    "dengue_df['CLASSI_FIN'] = dengue_df['CLASSI_FIN'].astype('category')\n",
    "\n",
    "dengue_df['CLASSI_FIN'] = dengue_df['CLASSI_FIN'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edcaec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert age code to years\n",
    "def extract_age_in_years(x):\n",
    "    tipo = x // 1000\n",
    "    valor = x % 1000\n",
    "    return valor if tipo == 4 else valor / 12 if tipo == 3 else 0\n",
    "\n",
    "dengue_df['age_years'] = dengue_df['NU_IDADE_N'].apply(extract_age_in_years).astype(int)\n",
    "dengue_df = dengue_df[dengue_df[\"age_years\"] <= 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fff373",
   "metadata": {},
   "source": [
    "* Plotting the distribution of cases per final classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 6))\n",
    "sns.countplot(data=dengue_df, x='age_years', hue='CLASSI_FIN', palette='Set2')\n",
    "plt.title('Distribution of cases per final classification')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of cases')\n",
    "plt.legend(title='Final Classification')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c91ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_age_group(age_years):\n",
    "    if pd.isnull(age_years):\n",
    "        return 'Ignored'\n",
    "    elif age_years < 1:\n",
    "        return '<1 year'\n",
    "    elif 1 <= age_years <= 4:\n",
    "        return '1-4 years'\n",
    "    elif 5 <= age_years <= 9:\n",
    "        return '5-9 years'\n",
    "    elif 10 <= age_years <= 14:\n",
    "        return '10-14 years'\n",
    "    elif 15 <= age_years <= 19:\n",
    "        return '15-19 years'\n",
    "    elif 20 <= age_years <= 39:\n",
    "        return '20-39 years'\n",
    "    elif 40 <= age_years <= 59:\n",
    "        return '40-59 years'\n",
    "    elif age_years >= 60:\n",
    "        return '60+ years'\n",
    "    else:\n",
    "        return 'Ignored'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e535a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df['age_range'] = dengue_df['age_years'].apply(classify_age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceae44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df['age_range'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d274f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "sns.countplot(data=dengue_df, x='age_range', hue='CLASSI_FIN', palette='Set2')\n",
    "plt.title('Distribution of final classifications per age group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Number of cases')\n",
    "plt.legend(title='Final Classification')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccba869",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_order = [\n",
    "    '<1 year',\n",
    "    '1-4 years',\n",
    "    '5-9 years',\n",
    "    '10-14 years',\n",
    "    '15-19 years',\n",
    "    '20-39 years',\n",
    "    '40-59 years',\n",
    "    '60+ years'\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.countplot(data=dengue_df, x='age_range', hue='CLASSI_FIN', palette='Set2', order=age_order)\n",
    "plt.title('Distribution of final classifications per age group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Number of cases')\n",
    "plt.legend(title='Final Classification')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN by a label\n",
    "dengue_df['CS_SEXO_PLOT'] = dengue_df['CS_SEXO'].fillna('Ignored')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=dengue_df, x='CS_SEXO_PLOT', palette='Set2')\n",
    "plt.title('Distribution of cases per sex')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Number of cases')\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9140e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_uf_to_region = {\n",
    "    11: 'Norte', 12: 'Norte', 13: 'Norte', 14: 'Norte', 15: 'Norte', 16: 'Norte', 17: 'Norte',\n",
    "    21: 'Nordeste', 22: 'Nordeste', 23: 'Nordeste', 24: 'Nordeste', 25: 'Nordeste',\n",
    "    26: 'Nordeste', 27: 'Nordeste', 28: 'Nordeste', 29: 'Nordeste',\n",
    "    31: 'Sudeste', 32: 'Sudeste', 33: 'Sudeste', 35: 'Sudeste',\n",
    "    41: 'Sul', 42: 'Sul', 43: 'Sul',\n",
    "    50: 'Centro-Oeste', 51: 'Centro-Oeste', 52: 'Centro-Oeste', 53: 'Centro-Oeste'\n",
    "}\n",
    "\n",
    "# Aplica o mapeamento\n",
    "dengue_df['REGION'] = dengue_df['SG_UF'].map(mapping_uf_to_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df = dengue_df.dropna(subset=['REGION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=dengue_df, x='REGION', hue='CLASSI_FIN', palette='Set2')\n",
    "plt.title('Distribution of cases per region and final classification')\n",
    "plt.xlabel('REGION')\n",
    "plt.ylabel('Númber of cases')\n",
    "plt.legend(title='Final classification')\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c23cda4",
   "metadata": {},
   "source": [
    "Removing useless columns, such as `ID_AGRAVO` which has only 1 fixed value: `A90`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba2927",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df = dengue_df.drop(columns=[\"CS_ESCOL_N\", \"NU_IDADE_N\", \"DT_NASC\", \"DT_SIN_PRI\", \"DT_NOTIFIC\", \"DT_INVEST\", \"DT_ENCERRA\"])\n",
    "dengue_df = dengue_df.drop(columns=[\"Unnamed: 0\", \"Unnamed: 0.1\"], errors='ignore')\n",
    "dengue_df = dengue_df.drop(columns=['ID_AGRAVO'])\n",
    "dengue_df = dengue_df.drop(columns=['SG_UF', 'SG_UF_NOT', 'ID_MUNICIP', 'ID_REGIONA', 'ID_UNIDADE', 'ID_MN_RESI', 'ID_RG_RESI', 'ID_PAIS'])\n",
    "dengue_df = dengue_df.drop(columns=['CS_RACA', 'COMUNINF', 'COPAISINF', 'COUFINF', 'COUFINF'])\n",
    "dengue_df = dengue_df.drop(columns=['SEM_NOT', 'NU_ANO', 'RESUL_SORO', 'RESUL_NS1', 'RESUL_VI_N', 'RESUL_PCR_', 'HISTOPA_N', 'IMUNOH_N','EVOLUCAO', 'TPAUTOCTO', 'HOSPITALIZ', 'idade_anos'])\n",
    "dengue_df = dengue_df.drop(columns=['SEM_PRI'])\n",
    "dengue_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66454f7",
   "metadata": {},
   "source": [
    "### Null data padding with default values:\n",
    "The resulting attributes that still had null data were entered with the default values referring to the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14aa0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'SEM_NOT': 'category',\n",
    "    'NU_ANO': 'int16',\n",
    "    'SG_UF_NOT': 'category',\n",
    "    'ID_MUNICIP': 'category',\n",
    "    'ID_REGIONA': 'category',\n",
    "    'ID_UNIDADE': 'category',\n",
    "    'SEM_PRI': 'int32',\n",
    "    'NU_IDADE_N': 'int8',\n",
    "    'CS_SEXO': 'category',\n",
    "    'CS_GESTANT': 'category',\n",
    "    'CS_RACA': 'category',\n",
    "    'CS_ESCOL_N': 'category',\n",
    "    'SG_UF': 'category',\n",
    "    'ID_MN_RESI': 'category',\n",
    "    'ID_RG_RESI': 'category',\n",
    "    'ID_PAIS': 'category',\n",
    "    'FEBRE': 'category',\n",
    "    'MIALGIA': 'category',\n",
    "    'CEFALEIA': 'category',\n",
    "    'EXANTEMA': 'category',\n",
    "    'VOMITO': 'category',\n",
    "    'NAUSEA': 'category',\n",
    "    'DOR_COSTAS': 'category',\n",
    "    'CONJUNTVIT': 'category',\n",
    "    'ARTRITE': 'category',\n",
    "    'ARTRALGIA': 'category',\n",
    "    'PETEQUIA_N': 'category',\n",
    "    'LEUCOPENIA': 'category',\n",
    "    'LACO': 'category',\n",
    "    'DOR_RETRO': 'category',\n",
    "    'DIABETES': 'category',\n",
    "    'HEMATOLOG': 'category',\n",
    "    'HEPATOPAT': 'category',\n",
    "    'RENAL': 'category',\n",
    "    'HIPERTENSA': 'category',\n",
    "    'ACIDO_PEPT': 'category',\n",
    "    'AUTO_IMUNE': 'category',\n",
    "    'RESUL_SORO': 'category',\n",
    "    'RESUL_NS1': 'category',\n",
    "    'RESUL_VI_N': 'category',\n",
    "    'RESUL_PCR_': 'category',\n",
    "    'HISTOPA_N': 'category',\n",
    "    'IMUNOH_N': 'category',\n",
    "    'HOSPITALIZ': 'category',\n",
    "    'TPAUTOCTO': 'category',\n",
    "    'COUFINF': 'category',\n",
    "    'COPAISINF': 'category',\n",
    "    'COMUNINF': 'category',\n",
    "    'EVOLUCAO': 'category',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df = process_num_like_cols(dengue_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7487e4",
   "metadata": {},
   "source": [
    "### Setting dtypes to columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0499de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_cols = ['DT_NOTIFIC', 'DT_SIN_PRI', 'DT_NASC', 'DT_INVEST', 'DT_ENCERRA']\n",
    "# for col in date_cols:\n",
    "#     if col in dengue_df.columns:\n",
    "#         dengue_df[col] = pd.to_datetime(dengue_df[col], errors='coerce')\n",
    "\n",
    "# dengue_df['SEM_PRI'] = dengue_df['SEM_PRI'].apply(lambda x: x.replace('-', '') if isinstance(x, str) else x)\n",
    "\n",
    "# exam_cols = [\n",
    "#     \"RESUL_SORO\",\n",
    "#     \"RESUL_NS1\",\n",
    "#     \"RESUL_VI_N\",\n",
    "#     \"RESUL_PCR_\",\n",
    "#     \"HISTOPA_N\",\n",
    "#     \"IMUNOH_N\"\n",
    "# ]\n",
    "# for col in exam_cols:\n",
    "#     if dengue_df[col].isnull().sum() > 0:\n",
    "#         dengue_df.loc[dengue_df[col].isnull(), col] = 4\n",
    "\n",
    "# dengue_df['CS_SEXO'] = dengue_df['CS_SEXO'].fillna('I')\n",
    "\n",
    "# # In the other attributes, the value of \"not informed\" is 9.\n",
    "# columns_to_be_filled = [\n",
    "#     col\n",
    "#     for col in dengue_df.columns\n",
    "#     if col not in exam_cols\n",
    "#     and 'DT_' not in str(col) # for datetime columns it doesn't make sense\n",
    "#     and not 'CS_SEXO'.__eq__(str(col)) # CS_SEXO has the special value 'I' for NaNs\n",
    "# ]\n",
    "# for col in columns_to_be_filled:\n",
    "#     if dengue_df[col].isnull().sum() > 0:\n",
    "#         dengue_df.loc[dengue_df[col].isnull(), col] = 9\n",
    "\n",
    "# dengue_df = dengue_df.astype(dtypes)\n",
    "\n",
    "dengue_df['CS_SEXO'] = dengue_df['CS_SEXO'].replace('I', np.nan)\n",
    "dengue_df = dengue_df.dropna(subset=['CS_SEXO'])\n",
    "dengue_df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67c7151",
   "metadata": {},
   "source": [
    "### Data normalization and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e49376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize CS_GESTANT\n",
    "def binarize_gestant(x):\n",
    "    if pd.isnull(x) or x == 9:\n",
    "        return 0\n",
    "    elif x in [1, 2, 3, 4]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "dengue_df['CS_GESTANT'] = dengue_df['CS_GESTANT'].apply(binarize_gestant)\n",
    "\n",
    "# Consider age_group and region as categories\n",
    "dengue_df['age_range'] = dengue_df['age_range'].astype('category')\n",
    "dengue_df['REGION'] = dengue_df['REGION'].astype('category')\n",
    "\n",
    "# Generate dummies with dummy_na=True (keep NaNs as explicit category)\n",
    "dengue_df = pd.get_dummies(dengue_df, columns=['age_range', 'REGION'], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00df16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df['CS_GESTANT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efcd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize target class\n",
    "dengue_df['CLASSI_FIN'] = dengue_df['CLASSI_FIN'].map({'Dengue': 1, 'Discarded/Inconclusive': 0})\n",
    "dengue_df['CLASSI_FIN'] = dengue_df['CLASSI_FIN'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a299a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = dengue_df.select_dtypes(include=['number', 'bool'])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(24, 20))\n",
    "sns.heatmap(correlation_matrix, annot=True, mask=mask, fmt=\".2f\", cmap=\"Blues\", square=True)\n",
    "plt.title(\"Correlation Matrix - Numeric Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df.drop(columns=['REGION_nan', 'REGION_Sul', 'age_range_nan', 'age_range_<1 year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e8613",
   "metadata": {},
   "source": [
    "### Saving processed DataFrame to parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8584b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df.to_parquet(\"./preprocessed_data/dengue.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c55045",
   "metadata": {},
   "source": [
    "## Reading Parquet File:\n",
    "---\n",
    "* Uncomment the cell below if you already have the `.parquet` file and just want to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df = pd.read_parquet(\"./preprocessed_data/dengue.parquet\")\n",
    "\n",
    "dtypes = {\n",
    "    'SEM_NOT': 'int32', 'NU_ANO': 'int16', 'SG_UF_NOT': 'category', 'ID_MUNICIP': 'category',\n",
    "    'ID_REGIONA': 'category', 'ID_UNIDADE': 'category', 'SEM_PRI': 'int32',\n",
    "    'NU_IDADE_N': 'int8', 'CS_SEXO': 'category', 'CS_GESTANT': 'category',\n",
    "    'CS_RACA': 'category', 'CS_ESCOL_N': 'category', 'SG_UF': 'category',\n",
    "    'ID_MN_RESI': 'category', 'ID_RG_RESI': 'category', 'ID_PAIS': 'category',\n",
    "    'FEBRE': 'category', 'MIALGIA': 'category', 'CEFALEIA': 'category',\n",
    "    'EXANTEMA': 'category', 'VOMITO': 'category', 'NAUSEA': 'category',\n",
    "    'DOR_COSTAS': 'category', 'CONJUNTVIT': 'category', 'ARTRITE': 'category',\n",
    "    'ARTRALGIA': 'category', 'PETEQUIA_N': 'category', 'LEUCOPENIA': 'category',\n",
    "    'LACO': 'category', 'DOR_RETRO': 'category', 'DIABETES': 'category',\n",
    "    'HEMATOLOG': 'category', 'HEPATOPAT': 'category', 'RENAL': 'category',\n",
    "    'HIPERTENSA': 'category', 'ACIDO_PEPT': 'category', 'AUTO_IMUNE': 'category',\n",
    "    'RESUL_SORO': 'category', 'RESUL_NS1': 'category', 'RESUL_VI_N': 'category',\n",
    "    'RESUL_PCR_': 'category', 'HISTOPA_N': 'category', 'IMUNOH_N': 'category',\n",
    "    'HOSPITALIZ': 'category', 'TPAUTOCTO': 'category', 'COUFINF': 'category',\n",
    "    'COPAISINF': 'category', 'COMUNINF': 'category', 'EVOLUCAO': 'category',\n",
    "}\n",
    "\n",
    "dengue_df = dengue_df.astype(dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab2d440",
   "metadata": {},
   "source": [
    "## Removing Data Leakage Features:\n",
    "---\n",
    "Some features in the dataset have information from the future (*i.e.* after the `CLASSI_FIN` has been diagnosed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8669d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_columns = [\n",
    "    'RESUL_SORO', 'RESUL_NS1', 'RESUL_VI_N', 'RESUL_PCR_', 'HISTOPA_N',\n",
    "    'IMUNOH_N', 'EVOLUCAO', 'DT_ENCERRA', 'TPAUTOCTO', 'COUFINF', 'COPAISINF',\n",
    "    'COMUNINF', 'CODISINF', 'CO_BAINFC', 'NOBAIINF', 'DOENCA_TRA', 'DT_OBITO',\n",
    "    \n",
    "]\n",
    "leaky_columns = [col for col in leaky_columns if col in dengue_df.columns]\n",
    "\n",
    "dengue_df = dengue_df.drop(columns=leaky_columns)\n",
    "\n",
    "# Already removed\n",
    "# dengue_df = dengue_df[~dengue_df[\"NU_IDADE_N\"] < 0] # Age < 0 don't make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778b8f3",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "---\n",
    "* Trying to extract useful information from features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1086c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'CS_SEXO','CS_GESTANT', 'FEBRE', 'MIALGIA', 'CEFALEIA', 'EXANTEMA', 'VOMITO', 'NAUSEA', \n",
    "    'DOR_COSTAS', 'CONJUNTVIT', 'ARTRITE', 'ARTRALGIA', 'PETEQUIA_N', 'LEUCOPENIA', 'LACO', \n",
    "    'DOR_RETRO', 'DIABETES', 'HEMATOLOG', 'HEPATOPAT', 'RENAL', 'HIPERTENSA', 'ACIDO_PEPT', \n",
    "    'AUTO_IMUNE'\n",
    "]\n",
    "\n",
    "dengue_df['CS_SEXO'] = dengue_df['CS_SEXO'].map({'M': 1, 'F': 0})\n",
    "\n",
    "# Treatment as discussed:\n",
    "# - For CS_SEXO: create category 2 for nulls\n",
    "# dengue_df['CS_SEXO'] = dengue_df['CS_SEXO'].fillna(2).astype(int)\n",
    "\n",
    "# - For CS_GESTANT: create category 0 for nulls\n",
    "dengue_df['CS_GESTANT'] = dengue_df['CS_GESTANT'].fillna(0).astype(int)\n",
    "\n",
    "# - For symptoms and comorbidities: binarize the columns (1 for yes, 0 for no/other)\n",
    "symptoms_comorbidities = cols.copy()\n",
    "symptoms_comorbidities.remove('CS_SEXO')\n",
    "symptoms_comorbidities.remove('CS_GESTANT')\n",
    "\n",
    "for col in symptoms_comorbidities:\n",
    "    # Set to 1 if the original value is 1, otherwise set to 0\n",
    "    dengue_df[col] = dengue_df[col].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86166ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df['FEBRE'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a4c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with error: 'DT_SIN_PRI' cannot be equal to 'DT_NASC'.\n",
    "dengue_df = dengue_df[~(dengue_df['DT_NASC'] == dengue_df['DT_SIN_PRI'])]\n",
    "\n",
    "# Time gap between notification and first simptoms.\n",
    "dengue_df['time_until_report'] = (dengue_df['DT_NOTIFIC'] - dengue_df['DT_SIN_PRI']).dt.days\n",
    "\n",
    "# Negative values for 'time_until_report' or 'time_until_report' >= 30 doesn't make sense, since the virus\n",
    "# expresses their simptoms in a shorter period of time.\n",
    "dengue_df = dengue_df.loc[(dengue_df['time_until_report'] <= 30) & (dengue_df['time_until_report'] >= 0)]\n",
    "\n",
    "# 'SEM_NOT' is the epidemiological week of the notification date.\n",
    "# We don't need the year, so we can convert it to a string and remove the first characters.\n",
    "dengue_df['SEM_NOT'] = dengue_df['SEM_NOT'].astype('str')\n",
    "dengue_df['SEM_NOT'] = dengue_df['SEM_NOT'].apply(lambda x: x[4:] if len(x) > 4 else x[2:])\n",
    "dengue_df['SEM_NOT'] = dengue_df['SEM_NOT'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=dengue_df['time_until_report'], orient='horizontal')\n",
    "plt.title('Distribuição de \"time_until_report\"')\n",
    "plt.xlabel('Dias entre Sintomas e Notificação')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = dengue_df.select_dtypes(include=['number', 'bool'])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Plotar o heatmap\n",
    "plt.figure(figsize=(24, 20))\n",
    "sns.heatmap(correlation_matrix, annot=True, mask=mask, fmt=\".2f\", cmap=\"Blues\", square=True)\n",
    "plt.title(\"Correlation Matrix - Numeric Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f1bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df = dengue_df.drop(columns=[\"CS_SEXO_PLOT\"], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_csv(\"raw_data/arbovirus_clinical_data/attributes.csv\", sep=\",\", header=0, low_memory=False)\n",
    "attributes = attributes.ffill()\n",
    "attributes = attributes.groupby([\"Attribute\", \"Description\"])[\"Value\"].apply('; '.join).reset_index(name=\"Values\")\n",
    "attributes = attributes[~attributes[\"Attribute\"].isin(leaky_columns)]\n",
    "attributes = attributes[attributes[\"Attribute\"].isin(dengue_df.columns)]\n",
    "attributes = attributes.reset_index(drop=True)\n",
    "\n",
    "acido_pept = {\n",
    "    \"Attribute\": \"ACIDO_PEPT\",\n",
    "    \"Description\": \"Pre-existing disease - Acid peptic disease\",\n",
    "    \"Values\": \"1: Yes; 2: No\",\n",
    "}\n",
    "\n",
    "time_until_report = {\n",
    "    \"Attribute\": \"time_until_report\",\n",
    "    \"Description\": \"Time until report\",\n",
    "    \"Values\": \"0: 0 days; 1: 1 day; 2: 2 days; ...; 30: 30 days\",\n",
    "}\n",
    "attributes = pd.concat([attributes, pd.DataFrame([acido_pept]), pd.DataFrame([time_until_report])], ignore_index=True)\n",
    "\n",
    "attributes.to_csv(\"preprocessed_data/attributes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d1e6b",
   "metadata": {},
   "source": [
    "## First attempt to train and test (using only LightGBM):\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30903521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(dengue_df['CLASSI_FIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep mapping of target variable\n",
    "target_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(f\"Target mapping: {target_mapping}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78260c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the feature matrix\n",
    "X = dengue_df.drop(columns=['CLASSI_FIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b96f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting month and day of the week from the notification date\n",
    "if 'DT_NOTIFIC' in X.columns:\n",
    "    X['notif_month'] = X['DT_NOTIFIC'].dt.month\n",
    "    X['notif_week_day'] = X['DT_NOTIFIC'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db22e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove raw date columns\n",
    "cols_to_drop = [col for col in X.columns if 'DT_' in col]\n",
    "X = X.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features to train with:\")\n",
    "print_with_multiple_columns(X.columns.tolist(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-checking for 'object' columns and converting them to appropriate types\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4cab2f",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning In a Small Subset:\n",
    "---\n",
    "* Instead of using 12 million registries, we will do Hyperparameter Tuning using only 500k samples, to save time and computer power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting optuna objective function\n",
    "def objective_parallel(trial, X_inner, y_inner):\n",
    "    \"\"\"\n",
    "    Versão otimizada para paralelismo. Cada trial usará apenas 1 core.\n",
    "    \"\"\"\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_inner, y_inner, test_size=0.25, random_state=42, stratify=y_inner\n",
    "    )\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': len(np.unique(y_inner)),\n",
    "        'verbosity': -1, 'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'n_jobs': 1,\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params, n_estimators=1000)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='multi_logloss',\n",
    "        callbacks=[lgb.early_stopping(15, verbose=False)]\n",
    "    )\n",
    "\n",
    "    preds = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, preds, average='macro')\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc1d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on a small subset\n",
    "# Stratified sampling for training...\n",
    "dengue_df['strata'] = (\n",
    "    dengue_df['NU_ANO'].astype(str) + '_' +\n",
    "    dengue_df['CLASSI_FIN'].astype(str)\n",
    ")\n",
    "\n",
    "# We will use a large ~ 5% (500k) sample size to ensure we have enough data for training.\n",
    "sample_size = 500_000\n",
    "sample_ratio = sample_size / len(dengue_df)\n",
    "\n",
    "_, df_subset = train_test_split(\n",
    "    dengue_df,\n",
    "    test_size=sample_ratio,\n",
    "    stratify=dengue_df['strata'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Sample subset created with size:\", len(df_subset))\n",
    "\n",
    "df_subset = df_subset.drop(columns=['strata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b3490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df_subset['CLASSI_FIN'])\n",
    "\n",
    "# Keep mapping of target variable\n",
    "target_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(f\"Target mapping: {target_mapping}\")\n",
    "\n",
    "# Preparing the feature matrix\n",
    "X = df_subset.drop(columns=['CLASSI_FIN'])\n",
    "\n",
    "# Extracting month and day of the week from the notification date\n",
    "if 'DT_NOTIFIC' in X.columns:\n",
    "    X['notif_month'] = X['DT_NOTIFIC'].dt.month\n",
    "    X['notif_week_day'] = X['DT_NOTIFIC'].dt.dayofweek\n",
    "    \n",
    "# Remove raw date columns\n",
    "cols_to_drop = [col for col in X.columns if 'DT_' in col]\n",
    "X = X.drop(columns=cols_to_drop)\n",
    "\n",
    "# Double-checking for 'object' columns and converting them to appropriate types\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e035041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested Cross Validation:\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=100)\n",
    "\n",
    "outer_scores = []\n",
    "best_params_per_fold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Nested Cross Validation...\")\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "    print(f\"\\n--- Processing over external fold {i+1}/5 ---\")\n",
    "    \n",
    "    X_train_outer, X_test_outer = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_outer, y_test_outer = y[train_idx], y[test_idx]\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(\n",
    "        lambda trial: objective_parallel(trial, X_train_outer, y_train_outer),\n",
    "        n_trials=20,  # You can adjust the number of trials based on your computational resources\n",
    "        n_jobs=-1     # <-- Here we use all available cores for parallel execution\n",
    "    )\n",
    "\n",
    "    best_params = study.best_trial.params\n",
    "    best_params['n_jobs'] = 1 \n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "    final_model = lgb.LGBMClassifier(**best_params, n_estimators=1000, random_state=42)\n",
    "    \n",
    "    final_model.fit(\n",
    "        X_train_outer, y_train_outer,\n",
    "        eval_set=[(X_test_outer, y_test_outer)],\n",
    "        eval_metric='multi_logloss',\n",
    "        callbacks=[lgb.early_stopping(15, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    y_pred_outer = final_model.predict(X_test_outer)\n",
    "    score = f1_score(y_test_outer, y_pred_outer, average='macro')\n",
    "    outer_scores.append(score)\n",
    "    print(f\"F1-Macro for External Fold: {i+1}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77cab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Final Evaluation of the Optimized Nested Cross-Validation ---\")\n",
    "print(f\"Macro F1-Scores for each outer fold: {np.round(outer_scores, 4)}\")\n",
    "print(f\"Mean Macro F1-Score: {np.mean(outer_scores):.4f}\")\n",
    "print(f\"Macro F1-Score Standard Deviation: {np.std(outer_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SIMPLIFY WITH A SINGLE SPLIT ---\n",
    "# We don't need Nested CV to find the leak\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- STEP 1: TRAIN A MODEL AND CHECK FEATURE IMPORTANCE ---\n",
    "print(\"Training a LightGBM model for importance analysis...\")\n",
    "simple_lgbm = lgb.LGBMClassifier(objective='multiclass', random_state=42)\n",
    "simple_lgbm.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- FEATURE IMPORTANCE PLOT (LGBM) ---\")\n",
    "print(\"Look for a bar that is MUCH taller than all the others.\")\n",
    "lgb.plot_importance(simple_lgbm, max_num_features=20, figsize=(10, 8),\n",
    "                    importance_type='gain', title='Feature Importance (Gain)')\n",
    "plt.show()\n",
    "\n",
    "# The feature name at the top of the plot is our SUSPECT #1.\n",
    "\n",
    "# --- STEP 2: VISUALIZE A SIMPLE DECISION TREE ---\n",
    "print(\"\\n--- SIMPLE DECISION TREE PLOT ---\")\n",
    "print(\"The feature at the top of the tree (root node) is the most likely culprit.\")\n",
    "# We need an X with only numeric columns for plot_tree\n",
    "X_train_numeric = X_train.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "simple_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "simple_tree.fit(X_train_numeric, y_train)\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plot_tree(simple_tree,\n",
    "          feature_names=X_train_numeric.columns,\n",
    "          class_names=le.classes_,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title(\"Simple Decision Tree to Identify the Dominant Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0db170",
   "metadata": {},
   "source": [
    "## Second attempt to train and test (multiple models) - Final version (used in the article):\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc16f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 10% of the data\n",
    "dengue_sample = resample(dengue_df, replace=False, n_samples=int(len(dengue_df) * 0.1), random_state=42)\n",
    "\n",
    "# Separate X and y\n",
    "X = dengue_sample.drop(columns=['CLASSI_FIN', 'REGION_Sudeste', 'age_group_60+ years', 'age_group_40-59 years', 'age_group_20-39 years', 'age_group_15-19 years', 'age_group_10-14 years', 'age_group_5-9 years', 'age_group_1-4 years', 'REGION_Norte', 'REGION_Nordeste', 'REGION_Centro-Oeste'])\n",
    "y = dengue_sample['CLASSI_FIN'].astype(int)\n",
    "\n",
    "# Standardization for linear models\n",
    "X_scaled = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics\n",
    "scoring = ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro', 'roc_auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d6a03",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba3fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "results_rf = cross_validate(model_rf, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "for metric in scoring:\n",
    "    mean = results_rf[f'test_{metric}'].mean()\n",
    "    std = results_rf[f'test_{metric}'].std()\n",
    "    print(f\"Random Forest {metric}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfde488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância das features\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Organizar em DataFrame para visualização\n",
    "feat_imp = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feat_imp[\"Feature\"], feat_imp[\"Importance\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Feature Importance - Random Forest\")\n",
    "plt.xlabel(\"Information Gain (Gini)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e22af87",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c589531",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "results_lr = cross_validate(model_lr, X_scaled, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "for metric in scoring:\n",
    "    mean = results_lr[f'test_{metric}'].mean()\n",
    "    std = results_lr[f'test_{metric}'].std()\n",
    "    print(f\"Logistic Regression {metric}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387827f2",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ec93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_svm = LinearSVC(max_iter=1000, random_state=42)\n",
    "results_svm = cross_validate(model_svm, X_scaled, y, cv=cv, scoring=scoring)\n",
    "\n",
    "for metric in scoring:\n",
    "    mean = results_svm[f'test_{metric}'].mean()\n",
    "    std = results_svm[f'test_{metric}'].std()\n",
    "    print(f\"Linear SVM {metric}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193cf221",
   "metadata": {},
   "source": [
    "#### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6140765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_lgbm = LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "results_lgbm = cross_validate(model_lgbm, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "for metric in scoring:\n",
    "    mean = results_lgbm[f'test_{metric}'].mean()\n",
    "    std = results_lgbm[f'test_{metric}'].std()\n",
    "    print(f\"LightGBM {metric}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a49d69",
   "metadata": {},
   "source": [
    "#### Model extra evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dengue_sample.drop(columns=['CLASSI_FIN', 'REGION_Sudeste', 'age_group_60+ years', 'age_group_40-59 years', 'age_group_20-39 years', 'age_group_15-19 years', 'age_group_10-14 years', 'age_group_5-9 years', 'age_group_1-4 years', 'REGION_Norte', 'REGION_Nordeste', 'REGION_Centro-Oeste'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d00ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1601f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09392dd1",
   "metadata": {},
   "source": [
    "##### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed737cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33752de",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"CLASSI_\", shap_values.values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd7060",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
